# -*- coding: utf-8 -*-
"""RDF-Extraction-and-Comparisson.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BOqT0lm30piLCR-SHHRTGvG-Oa-rojOM

# RDF Triple extraction and Comparison

# Setup
"""

!pip install transformers
!pip install pdfx
!pip install aspose-pdf
!pip install docx
!pip install python-docx

"""*extract_triplets_typed(text)* is a function implemented from babelscape/mrebel-large tokenizer, this is the function that extracts and formats the RDF triples from a text given as input"""

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

def extract_triplets_typed(text):
    triplets = []
    relation = ''
    text = text.strip()
    current = 'x'
    subject, relation, object_, object_type, subject_type = '','','','',''

    for token in text.replace("<s>", "").replace("<pad>", "").replace("</s>", "").replace("tp_XX", "").replace("__en__", "").split():
        if token == "<triplet>" or token == "<relation>":
            current = 't'
            if relation != '':
                triplets.append({'subject': subject.strip(), 'subject_type': subject_type, 'predicate': relation.strip(),'object': object_.strip(), 'object_type': object_type})
                relation = ''
            subject = ''
        elif token.startswith("<") and token.endswith(">"):
            if current == 't' or current == 'o':
                current = 's'
                if relation != '':
                    triplets.append({'subject': subject.strip(), 'subject_type': subject_type, 'predicate': relation.strip(),'object': object_.strip(), 'object_type': object_type})
                object_ = ''
                subject_type = token[1:-1]
            else:
                current = 'o'
                object_type = token[1:-1]
                relation = ''
        else:
            if current == 't':
                subject += ' ' + token
            elif current == 's':
                object_ += ' ' + token
            elif current == 'o':
                relation += ' ' + token
    if subject != '' and relation != '' and object_ != '' and object_type != '' and subject_type != '':
        triplets.append({'subject': subject.strip(), 'subject_type': subject_type, 'predicate': relation.strip(),'object': object_.strip(), 'object_type': object_type})
    return triplets

# Load model and tokenizer
tokenizer = AutoTokenizer.from_pretrained("Babelscape/mrebel-large", src_lang="en_XX", tgt_lang="tp_XX")
# Here we set English ("en_XX") as source language. To change the source language swap the first token of the input for your desired language or change to supported language. For catalan ("ca_XX") or greek ("el_EL") (not included in mBART pretraining) you need a workaround:
# tokenizer._src_lang = "ca_XX"
# tokenizer.cur_lang_code_id = tokenizer.convert_tokens_to_ids("ca_XX")
# tokenizer.set_src_lang_special_tokens("ca_XX")
model = AutoModelForSeq2SeqLM.from_pretrained("Babelscape/mrebel-large")
gen_kwargs = {
    "max_length": 256,
    "length_penalty": 0,
    "num_beams": 3,
    "num_return_sequences": 3,
    "forced_bos_token_id": None,
}

"""*get_triplets_from_text(text)* is the function where the model parameters are setup, as a result it also concatinates the resulting triples in a list"""

def get_triplets_from_text(text):
  # Tokenizer text
  model_inputs = tokenizer(text, max_length=256, padding=True, truncation=True, return_tensors = 'pt')

  # Generate
  generated_tokens = model.generate(
      model_inputs["input_ids"].to(model.device),
      attention_mask=model_inputs["attention_mask"].to(model.device),
      decoder_start_token_id = tokenizer.convert_tokens_to_ids("tp_XX"),
      **gen_kwargs,
  )

  # Extract text
  decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)

  result = []
  # Extract triplets
  for idx, sentence in enumerate(decoded_preds):
      result.append(extract_triplets_typed(sentence))
  return result

"""*extract_triplets_from_file(file_name)* is a function where a file name is passed and it gets striped and split by sentances. Then triplets are extracted from each sentance and 2 lists are filled, triples which houses each unique triple and triples_count which houses the ammount of times said triple appears in the given file"""

import aspose.pdf as ap
from docx import Document
from docx.shared import Cm

def save_results_to_file(file_name, results):
  document = Document()
  style = document.styles['Normal']
  style.font.name = 'Calibri'

  header_section = document.sections[0]
  header = header_section.header
  header_text = header.paragraphs[0]
  header_text.text = "Result of " + file_name + " file"

  document.add_heading("These are the unique triples for the Test File", level=1)
  for batch in results:
    for sentance in batch:
      for triple in sentance:
        p = document.add_paragraph(str(triple))
        p = document.add_paragraph("-----------------------------")

  name = file_name + "_results.docx"
  document.save(name)

import pdfx
def extract_triplets_from_file(file_name):
  document = ap.Document()

  pdf = pdfx.PDFx(file_name)
  text = pdf.get_text()
  text = text.replace('\n', '')
  parts = text.split('.')
  triples = []
  percentage = 0
  for part in parts:
    percentage += 1
    progress = 100 * percentage/len(parts)
    print("%5.2f%%" % progress)
    results = get_triplets_from_text(part)
    triples.append(results)
  save_results_to_file(file_name, triples)
  return triples

"""*get_file_similarity(file1, file2)* is a function which takes 2 file names as paramaters and then extracts the rdf triple/triple count from both. It then calculates the frequency of which the same rdf triples appear within both files"""

def get_file_similarity(file1, file2):
  file1_results = extract_triplets_from_file(file1)
  file2_results = extract_triplets_from_file(file2)

  count_all = 0
  count_same = 0
  for triple in file1_results and file2_results:
    if triple in  file1_results:
      if triple in  file2_results:
        count_same += 1
  for count in file1_results:
    count_all += 1
  if count_all == 0:
    count_all = 1
  percentage = 100 * count_same/count_all
  return percentage

"""# Functionality
To use the system, simply call the *get_file_similarity(file1, file2)* function where the arguments are replaced with the paths to the files being compared. The files do need to be in the .pdf format to be used
"""

percentage = get_file_similarity("/content/drive/MyDrive/Collab Files/germany.pdf", "/content/drive/MyDrive/Collab Files/germany2.pdf")
print("The two files are %5.2f%% similar" % percentage)